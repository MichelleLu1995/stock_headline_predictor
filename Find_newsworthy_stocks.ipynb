{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "from nytimesarticle import articleAPI\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dateutil\n",
    "import time\n",
    "import quandl\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from pandas.tools.plotting import lag_plot\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "# extra API keys, comment out as necessary\n",
    "#api = articleAPI(\"b23351c6f9314694bfe4f4929a2b72c5\") \n",
    "#api = articleAPI(\"787bd4db8e704bbf9cebe8b7941827e0\") \n",
    "#api = articleAPI(\"f8b402f42ed14b249fd5accc95a050dd\") \n",
    "#api = articleAPI(\"c91a676aeaef40fd844409c8b0bef485\")\n",
    "#api = articleAPI(\"c43133d654134109868299ff505e7c55\")\n",
    "#api = articleAPI(\"eb427ebc2336423ead4d350cfa4e900b\")\n",
    "api = articleAPI(\"b538de93f1a9459da22b150d7b53cb6f\")\n",
    "#api = articleAPI(\"88f587ed149d4478b4490168d61ed9dc\")\n",
    "\n",
    "quandl.ApiConfig.api_key = \"2S7d7eeL5VZrLup9pKg5\"\n",
    "end_date = (datetime.datetime.now() - datetime.timedelta(days=3)).isoformat()\n",
    "start_date = (datetime.datetime.now() - datetime.timedelta(days=365)).isoformat()\n",
    "left_sources = 'The New York Times'\n",
    "right_sources = 'Fox News'\n",
    "center_sources = 'Reuters AP The Wall Street Journal'\n",
    "all_sources = left_sources + ' ' + right_sources + ' ' + center_sources\n",
    "replace_list = ['Corp', 'Inc.', 'Inc', '.com', 'plc', ',', 'Co.']\n",
    "# domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('constituents_csv.csv')\n",
    "companies = df['Name']\n",
    "company_symb = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MMM</td>\n",
       "      <td>3M Company</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOS</td>\n",
       "      <td>A.O. Smith Corp</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABT</td>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACN</td>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol                 Name                  Sector\n",
       "0    MMM           3M Company             Industrials\n",
       "1    AOS      A.O. Smith Corp             Industrials\n",
       "2    ABT  Abbott Laboratories             Health Care\n",
       "3   ABBV          AbbVie Inc.             Health Care\n",
       "4    ACN        Accenture plc  Information Technology"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc.</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Symbol             Name                  Sector\n",
       "30   AMZN  Amazon.com Inc.  Consumer Discretionary"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Name'] == 'Amazon.com Inc.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m company\n",
      "headline:(3m company) or body:(3m company) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "a.o. smith \n",
      "headline:(a.o. smith ) or body:(a.o. smith ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "abbott laboratories\n",
      "headline:(abbott laboratories) or body:(abbott laboratories) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "abbvie \n",
      "headline:(abbvie ) or body:(abbvie ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "accenture \n",
      "headline:(accenture ) or body:(accenture ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "activision blizzard\n",
      "headline:(activision blizzard) or body:(activision blizzard) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "acuity brands \n",
      "headline:(acuity brands ) or body:(acuity brands ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "adobe systems \n",
      "headline:(adobe systems ) or body:(adobe systems ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "advance auto parts\n",
      "headline:(advance auto parts) or body:(advance auto parts) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "advanced micro devices \n",
      "headline:(advanced micro devices ) or body:(advanced micro devices ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "aes \n",
      "headline:(aes ) or body:(aes ) and source:(the new york times fox news reuters ap the wall street journal)\n",
      "aetna \n",
      "headline:(aetna ) or body:(aetna ) and source:(the new york times fox news reuters ap the wall street journal)\n"
     ]
    }
   ],
   "source": [
    "# company = companies.loc[i]\n",
    "company_hits = []\n",
    "start_date = int(start_date.replace(\"-\",\"\").split('T')[0])\n",
    "ending_date = (dateutil.parser.parse(end_date)-datetime.timedelta(days=1)).isoformat()\n",
    "end_date = int(ending_date.replace(\"-\",\"\").split('T')[0])\n",
    "\n",
    "for company in companies:\n",
    "    try:\n",
    "        # get company ticker\n",
    "        company_symb[company] = df[df['Name'] == company]['Symbol']\n",
    "        ticker = company_symb[company].values[0]\n",
    "\n",
    "        # get rid of suffixes from company name\n",
    "        for word in replace_list:\n",
    "            company = company.replace(word, '')\n",
    "\n",
    "        newsdata = api.search(q=company, begin_date = start_date,\n",
    "                               end_date = end_date,\n",
    "                              fq='headline:('+company+ ') OR body:('+company+') AND source:(' + all_sources + ')',\n",
    "                              page = 0,\n",
    "                              facet_filter = True)\n",
    "\n",
    "        number_of_hits = newsdata['response']['meta']['hits']\n",
    "        company_hits.append(number_of_hits)\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        company_hits.append(0)\n",
    "        print(company, 'failed')\n",
    "        time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31, 22, 51, 31, 58, 28, 3, 24, 26, 22, 7, 193, 21, 4, 4, 0, 10, 83, 18, 100, 8, 100, 1, 32, 61, 1, 42, 85, 10, 36, 4125, 1, 368, 560, 306, 4641, 1364, 3877, 6, 9, 0, 47, 0, 17, 30, 12, 1, 1558, 36, 0, 0, 4111, 167, 0, 137, 35, 0, 4, 0, 12, 17, 4, 5, 1, 77, 7248, 1961, 16, 0, 0, 274, 3470, 28, 249, 0, 419, 19, 5, 119, 164, 2, 64, 142, 20, 29, 204, 0, 4, 45, 2600, 63, 11, 573, 145, 13, 22, 2142, 27, 0, 3, 43, 4, 3, 0, 133, 240, 37, 6, 0, 80, 0, 127, 0, 87, 598, 497, 0, 54, 3, 219, 7, 107, 409, 40, 5, 5, 39, 42, 23, 36, 33, 26, 21, 5, 34, 50, 112, 11, 7, 17, 12, 0, 376, 0, 50, 12, 64, 266, 35, 113, 950, 132, 27, 252, 12, 37, 6, 163, 7, 2, 539, 5, 0, 355, 2, 0, 0, 632, 13, 17, 12, 8, 0, 158, 3, 81, 2, 5, 20, 14, 23, 103, 0, 61, 80, 495, 1, 10779, 1, 289, 0, 1164, 7, 19, 3, 2, 0, 16, 0, 248, 452, 1, 0, 103, 96, 3547, 1, 100, 246, 1077, 90, 242, 878, 190, 29, 615, 776, 0, 0, 54, 6, 634, 1, 0, 63, 2, 2, 0, 4, 0, 78, 21, 6, 371, 0, 10, 0, 91, 126, 2, 7, 1, 5, 24, 9, 0, 1, 487, 78, 273, 1510, 9, 0, 52, 3, 2, 0, 0, 0, 474, 9, 0, 0, 36, 0, 14, 146, 162, 12055, 1879, 0, 41, 3, 0, 22, 74, 113, 80, 18, 39, 0, 25, 8, 0, 865, 0, 166, 44, 0, 6, 0, 5, 1, 110, 38, 0, 0, 2, 0, 121, 64, 0, 6, 72, 39, 0, 200, 1, 43, 16, 38, 22, 1288, 392, 1, 27, 67, 196, 5, 0, 724, 2, 7, 697, 1, 41, 0, 5, 2588, 27, 0, 0, 3771, 886, 23, 4, 469, 0, 82, 190, 43, 427, 33, 25, 17, 19, 0, 0, 16, 9, 2, 361, 1, 0, 1342, 2, 228, 1, 55, 108, 2, 16, 230, 0, 44, 72, 10, 33, 22, 60, 24, 19, 14, 204, 0, 2784, 6, 93, 0, 611, 1, 17, 0, 292, 0, 15, 601, 52, 46, 0, 591, 0, 27, 309, 374, 1, 604, 11, 31, 1, 127, 27, 0, 134, 1, 7, 1, 13, 214, 11, 4859, 55, 6, 6, 1518, 9882, 262, 0, 619, 6374, 2, 18, 12, 1, 57, 13, 1, 8, 465, 1756, 235, 7425, 0, 1, 101, 11, 4101, 11, 126, 81, 86, 349, 465, 8, 0, 1130, 10, 0, 424, 17, 0, 76, 3019, 646, 63, 20, 0, 13, 14, 485, 1102, 46, 3263, 89, 140, 1283, 165, 15, 7, 18, 4, 5, 3, 3, 328, 12, 279, 1436, 36, 6, 103, 17, 263, 1, 2, 932, 0, 411, 164, 2, 6, 104, 9, 15, 11, 16, 34, 110, 1, 25, 5, 55, 6, 3, 14]\n",
      "11\n",
      "4125\n"
     ]
    }
   ],
   "source": [
    "print((company_hits))\n",
    "print(sum(i > 4000 for i in company_hits))\n",
    "print(company_hits[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_news_articles(company, start_date, end_date, trading_dates, sources):\n",
    "    \"\"\" Queries news article for a certain time frame and split it by dates\n",
    "        Note that\n",
    "    Params:\n",
    "        company (String): Name of company\n",
    "        start_date (String): Start date in format of \"2001-12-31\"\n",
    "        end_date (String): End date in format of \"2001-12-31\"\n",
    "         trading_dates (Array of Strings): Array of dates when the market was open\n",
    "                 dates in format of \"2001-12-31\"\n",
    "        sources (Array of Strings): Array of different news sources\n",
    "    Returns:\n",
    "        company_dic (dictionary): keys are date, values are array of headlines\n",
    "    \"\"\"\n",
    "    company_dict = {k: [] for k in trading_dates.date}\n",
    "    start_date = int(start_date.replace(\"-\",\"\").split('T')[0])\n",
    "    ending_date = (dateutil.parser.parse(end_date)-datetime.timedelta(days=1)).isoformat()\n",
    "    end_date = int(ending_date.replace(\"-\",\"\").split('T')[0])\n",
    "    newsdata = api.search(q=company, begin_date = start_date,\n",
    "                           end_date = end_date,\n",
    "                          fq='headline:('+company+ ') OR body:('+company+') AND source:(' + sources + ')',\n",
    "                          page = 0,\n",
    "                          facet_filter = True)\n",
    "                               \n",
    "\n",
    "    #print(newsdata) # newsdata is full HTTP response\n",
    "    number_of_hits = newsdata['response']['meta']['hits']\n",
    "    number_of_pages = (number_of_hits // 10) + 1\n",
    "    \n",
    "    time.sleep(1)\n",
    "    # page through results and add headlines to companY_dict\n",
    "    for i in range(0, min(number_of_pages,200)):\n",
    "        print('page', i)\n",
    "        newsdata = api.search(q=company, begin_date = start_date,\n",
    "                           end_date = end_date,\n",
    "                          fq='headline:('+company+ ') OR body:('+company+') AND source:(' + sources + ')',\n",
    "                          page = i,\n",
    "                          facet_filter = True)\n",
    "        articles = newsdata['response']['docs']\n",
    "        for article in articles:\n",
    "            relevance = article['score']\n",
    "            if relevance >= 0.005: \n",
    "                headline = article['headline']['main']\n",
    "                blurb = article['snippet']\n",
    "                # print(article['pub_date'], '\\t', article['headline']['main'])\n",
    "            \n",
    "                # description = article['description']\n",
    "                # format of date is 2018-04-13T00:46:59Z (UTC format)\n",
    "                publish_date = article['pub_date'] \n",
    "                print(publish_date)\n",
    "                # adjust date for trading day\n",
    "                publish_date, publish_time = publish_date.split('T')\n",
    "                date_arr = publish_date.split('-')\n",
    "                publish_datetime = datetime.date(int(date_arr[0]), int(date_arr[1]), int(date_arr[2]))\n",
    "                time_arr = publish_time[:-1].split(':')\n",
    "                # stock market closes at 4:00 PM EST; if article published after \n",
    "                # 16:00:00+4:00:00 = 20:00:00 UTC headline affects next trading day;\n",
    "                # otherwise affects current trading day\n",
    "                trading_datetime = publish_datetime\n",
    "                if int(time_arr[0]) >= 20:\n",
    "                    trading_datetime += datetime.timedelta(days=1)\n",
    "                \n",
    "                # if given trading_date invalid (ie if article published on Friday \n",
    "                # after market close, Saturday, or Sunday before 4 pm est) push trading_date\n",
    "                # to the following Monday (ie first valid trading_date)\n",
    "                while trading_datetime not in trading_dates:\n",
    "                    trading_datetime += datetime.timedelta(1)\n",
    "                company_dict[trading_datetime].append(headline)\n",
    "                # company_dict[trading_datetime].append(blurb) include 'snippet' in sentiment analysis\n",
    "        time.sleep(1)\n",
    "        \n",
    "    return company_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
